{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quickstart: Compare runs, choose a model, and deploy it to a REST API\n",
    "\n",
    "In this quickstart, you will:\n",
    "\n",
    "- Run a hyperparameter sweep on a training script\n",
    "\n",
    "- Compare the results of the runs in the MLflow UI\n",
    "\n",
    "- Choose the best run and register it as a model\n",
    "\n",
    "- Deploy the model to a REST API\n",
    "\n",
    "- Build a container image suitable for deployment to a cloud platform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hyperopt import STATUS_OK,Trials,fmin,hp,tpe\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         8.8        6  \n",
       "1         9.5        6  \n",
       "2        10.1        6  \n",
       "3         9.9        6  \n",
       "4         9.9        6  \n",
       "...       ...      ...  \n",
       "4893     11.2        6  \n",
       "4894      9.6        5  \n",
       "4895      9.4        6  \n",
       "4896     12.8        7  \n",
       "4897     11.8        6  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load the dataset\n",
    "data=pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-white.csv\",\n",
    "    sep=\";\",\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.22</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.048</td>\n",
       "      <td>41.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.99256</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.29</td>\n",
       "      <td>16.85</td>\n",
       "      <td>0.054</td>\n",
       "      <td>23.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.99980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.38</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.27</td>\n",
       "      <td>7.50</td>\n",
       "      <td>0.041</td>\n",
       "      <td>24.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.99535</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.43</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.055</td>\n",
       "      <td>18.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.99170</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.47</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3338</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.28</td>\n",
       "      <td>15.20</td>\n",
       "      <td>0.046</td>\n",
       "      <td>6.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.99665</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.39</td>\n",
       "      <td>10.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4426</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.52</td>\n",
       "      <td>6.50</td>\n",
       "      <td>0.047</td>\n",
       "      <td>28.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.99418</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.32</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.039</td>\n",
       "      <td>54.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.43</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092</th>\n",
       "      <td>7.6</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.52</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.043</td>\n",
       "      <td>28.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0.99129</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.53</td>\n",
       "      <td>11.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.29</td>\n",
       "      <td>13.70</td>\n",
       "      <td>0.035</td>\n",
       "      <td>53.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>0.99567</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.38</td>\n",
       "      <td>10.6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.030</td>\n",
       "      <td>38.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.99255</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.63</td>\n",
       "      <td>10.4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3673 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "2835            6.3              0.25         0.22            3.30      0.048   \n",
       "1157            7.8              0.30         0.29           16.85      0.054   \n",
       "744             7.4              0.38         0.27            7.50      0.041   \n",
       "1448            7.4              0.16         0.49            1.20      0.055   \n",
       "3338            7.2              0.27         0.28           15.20      0.046   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4426            6.2              0.21         0.52            6.50      0.047   \n",
       "466             7.0              0.14         0.32            9.00      0.039   \n",
       "3092            7.6              0.27         0.52            3.20      0.043   \n",
       "3772            6.3              0.24         0.29           13.70      0.035   \n",
       "860             8.1              0.27         0.35            1.70      0.030   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "2835                 41.0                 161.0  0.99256  3.16       0.50   \n",
       "1157                 23.0                 135.0  0.99980  3.16       0.38   \n",
       "744                  24.0                 160.0  0.99535  3.17       0.43   \n",
       "1448                 18.0                 150.0  0.99170  3.23       0.47   \n",
       "3338                  6.0                  41.0  0.99665  3.17       0.39   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4426                 28.0                 123.0  0.99418  3.22       0.49   \n",
       "466                  54.0                 141.0  0.99560  3.22       0.43   \n",
       "3092                 28.0                 152.0  0.99129  3.02       0.53   \n",
       "3772                 53.0                 134.0  0.99567  3.17       0.38   \n",
       "860                  38.0                 103.0  0.99255  3.22       0.63   \n",
       "\n",
       "      alcohol  quality  \n",
       "2835     10.5        6  \n",
       "1157      9.0        6  \n",
       "744      10.0        5  \n",
       "1448     11.2        6  \n",
       "3338     10.9        6  \n",
       "...       ...      ...  \n",
       "4426      9.9        6  \n",
       "466       9.4        6  \n",
       "3092     11.4        6  \n",
       "3772     10.6        6  \n",
       "860      10.4        8  \n",
       "\n",
       "[3673 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Split the data into training,validation and test sets\n",
    "\n",
    "train,test=train_test_split(data,test_size=0.25,random_state=42)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 6, 5, ..., 6, 6, 8])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['quality']].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=train.drop(['quality'],axis=1).values\n",
    "train_y=train[['quality']].values.ravel()\n",
    "\n",
    "## test dataset\n",
    "test_x=test.drop(['quality'],axis=1).values\n",
    "test_y=test[['quality']].values.ravel()\n",
    "\n",
    "## splitting this train data into train and validation\n",
    "\n",
    "train_x,valid_x,train_y,valid_y=train_test_split(train_x,train_y,test_size=0.20,random_state=42)\n",
    "\n",
    "signature=infer_signature(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.86621852e+00, 2.80377808e-01, 3.32597005e-01, 6.42164738e+00,\n",
       "       4.55513955e-02, 3.53556841e+01, 1.38792376e+02, 9.94074221e-01,\n",
       "       3.18919333e+00, 4.88396869e-01, 1.05005673e+01])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_x,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANN Model\n",
    "\n",
    "def train_model(params,epochs,train_x,train_y,valid_x,valid_y,test_x,test_y):\n",
    "\n",
    "    ## Define model architecture\n",
    "    mean=np.mean(train_x,axis=0)\n",
    "    var=np.var(train_x,axis=0)\n",
    "\n",
    "    model=keras.Sequential(\n",
    "        [\n",
    "            keras.Input([train_x.shape[1]]),\n",
    "            keras.layers.Normalization(mean=mean,variance=var),\n",
    "            keras.layers.Dense(64,activation='relu'),\n",
    "            keras.layers.Dense(1)\n",
    "\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    ## compile the model\n",
    "    model.compile(optimizer=keras.optimizers.SGD(\n",
    "        learning_rate=params[\"lr\"],momentum=params[\"momentum\"]\n",
    "    ),\n",
    "    loss=\"mean_squared_error\",\n",
    "    metrics=[keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "\n",
    "    ## Train the ANN model with lr and momentum params wwith MLFLOW tracking\n",
    "    with mlflow.start_run(nested=True):\n",
    "        model.fit(train_x,train_y,validation_data=(valid_x,valid_y),\n",
    "                  epochs=epochs,\n",
    "                  batch_size=64)\n",
    "        \n",
    "        ## Evaluate the model\n",
    "        eval_result=model.evaluate(valid_x,valid_y,batch_size=64)\n",
    "\n",
    "        eval_rmse=eval_result[1]\n",
    "\n",
    "        ## Log the parameters and results\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric(\"eval_rmse\",eval_rmse)\n",
    "\n",
    "        ## log the model\n",
    "\n",
    "        mlflow.tensorflow.log_model(model,\"model\",signature=signature)\n",
    "\n",
    "        return {\"loss\": eval_rmse, \"status\": STATUS_OK, \"model\": model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # MLflow will track the parameters and results for each run\n",
    "    result = train_model(\n",
    "        params,\n",
    "        epochs=3,\n",
    "        train_x=train_x,\n",
    "        train_y=train_y,\n",
    "        valid_x=valid_x,\n",
    "        valid_y=valid_y,\n",
    "        test_x=test_x,\n",
    "        test_y=test_y,\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "space={\n",
    "    \"lr\":hp.loguniform(\"lr\",np.log(1e-5),np.log(1e-1)),\n",
    "    \"momentum\":hp.uniform(\"momentum\",0.0,1.0)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/29 13:46:22 INFO mlflow.tracking.fluent: Experiment with name 'wine-quality' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 13:46:23.321210: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2025-01-29 13:46:23.321592: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2025-01-29 13:46:23.322551: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2025-01-29 13:46:23.323789: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-01-29 13:46:23.324920: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                            \n",
      "\n",
      "  0%|          | 0/4 [00:04<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 13:46:29.447651: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-01-29 13:46:29.679915: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node SGD/AssignVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/46 [..............................] - ETA: 6:41 - loss: 35.3871 - root_mean_squared_error: 5.9487\n",
      " 4/46 [=>............................] - ETA: 0s - loss: 35.7069 - root_mean_squared_error: 5.9755  \n",
      " 8/46 [====>.........................] - ETA: 0s - loss: 36.1713 - root_mean_squared_error: 6.0143\n",
      "11/46 [======>.......................] - ETA: 0s - loss: 35.6980 - root_mean_squared_error: 5.9748\n",
      "14/46 [========>.....................] - ETA: 0s - loss: 35.4860 - root_mean_squared_error: 5.9570\n",
      "17/46 [==========>...................] - ETA: 0s - loss: 35.3787 - root_mean_squared_error: 5.9480\n",
      "20/46 [============>.................] - ETA: 0s - loss: 35.2732 - root_mean_squared_error: 5.9391\n",
      "24/46 [==============>...............] - ETA: 0s - loss: 35.3494 - root_mean_squared_error: 5.9455\n",
      "28/46 [=================>............] - ETA: 0s - loss: 35.3072 - root_mean_squared_error: 5.9420\n",
      "33/46 [====================>.........] - ETA: 0s - loss: 35.3259 - root_mean_squared_error: 5.9436\n",
      "38/46 [=======================>......] - ETA: 0s - loss: 35.1749 - root_mean_squared_error: 5.9308\n",
      "43/46 [===========================>..] - ETA: 0s - loss: 35.1933 - root_mean_squared_error: 5.9324\n",
      "46/46 [==============================] - ETA: 0s - loss: 35.0736 - root_mean_squared_error: 5.9223\n",
      "46/46 [==============================] - 13s 85ms/step - loss: 35.0736 - root_mean_squared_error: 5.9223 - val_loss: 34.3723 - val_root_mean_squared_error: 5.8628\n",
      "\n",
      "Epoch 2/3                                            \n",
      "\n",
      " 1/46 [..............................] - ETA: 1s - loss: 35.1208 - root_mean_squared_error: 5.9263\n",
      " 4/46 [=>............................] - ETA: 0s - loss: 35.0176 - root_mean_squared_error: 5.9176\n",
      " 8/46 [====>.........................] - ETA: 0s - loss: 35.0669 - root_mean_squared_error: 5.9217\n",
      "12/46 [======>.......................] - ETA: 0s - loss: 34.9925 - root_mean_squared_error: 5.9154\n",
      "16/46 [=========>....................] - ETA: 0s - loss: 35.1539 - root_mean_squared_error: 5.9291\n",
      "20/46 [============>.................] - ETA: 0s - loss: 35.0463 - root_mean_squared_error: 5.9200\n",
      "24/46 [==============>...............] - ETA: 0s - loss: 34.9922 - root_mean_squared_error: 5.9154\n",
      "28/46 [=================>............] - ETA: 0s - loss: 34.8339 - root_mean_squared_error: 5.9020\n",
      "29/46 [=================>............] - ETA: 0s - loss: 34.8665 - root_mean_squared_error: 5.9048\n",
      "30/46 [==================>...........] - ETA: 0s - loss: 34.9069 - root_mean_squared_error: 5.9082\n",
      "32/46 [===================>..........] - ETA: 0s - loss: 34.8252 - root_mean_squared_error: 5.9013\n",
      "34/46 [=====================>........] - ETA: 0s - loss: 34.8221 - root_mean_squared_error: 5.9010\n",
      "37/46 [=======================>......] - ETA: 0s - loss: 34.7024 - root_mean_squared_error: 5.8909\n",
      "40/46 [=========================>....] - ETA: 0s - loss: 34.5935 - root_mean_squared_error: 5.8816\n",
      "43/46 [===========================>..] - ETA: 0s - loss: 34.5267 - root_mean_squared_error: 5.8759\n",
      "46/46 [==============================] - 1s 24ms/step - loss: 34.4524 - root_mean_squared_error: 5.8696 - val_loss: 33.7613 - val_root_mean_squared_error: 5.8105\n",
      "\n",
      "Epoch 3/3                                            \n",
      "\n",
      " 1/46 [..............................] - ETA: 0s - loss: 35.5955 - root_mean_squared_error: 5.9662\n",
      " 6/46 [==>...........................] - ETA: 0s - loss: 33.9525 - root_mean_squared_error: 5.8269\n",
      "10/46 [=====>........................] - ETA: 0s - loss: 34.1671 - root_mean_squared_error: 5.8453\n",
      "14/46 [========>.....................] - ETA: 0s - loss: 33.8506 - root_mean_squared_error: 5.8181\n",
      "18/46 [==========>...................] - ETA: 0s - loss: 33.8515 - root_mean_squared_error: 5.8182\n",
      "22/46 [=============>................] - ETA: 0s - loss: 34.0807 - root_mean_squared_error: 5.8379\n",
      "26/46 [===============>..............] - ETA: 0s - loss: 33.9667 - root_mean_squared_error: 5.8281\n",
      "31/46 [===================>..........] - ETA: 0s - loss: 33.9120 - root_mean_squared_error: 5.8234\n",
      "35/46 [=====================>........] - ETA: 0s - loss: 33.9737 - root_mean_squared_error: 5.8287\n",
      "37/46 [=======================>......] - ETA: 0s - loss: 33.9644 - root_mean_squared_error: 5.8279\n",
      "40/46 [=========================>....] - ETA: 0s - loss: 33.8692 - root_mean_squared_error: 5.8197\n",
      "42/46 [==========================>...] - ETA: 0s - loss: 33.8291 - root_mean_squared_error: 5.8163\n",
      "44/46 [===========================>..] - ETA: 0s - loss: 33.8823 - root_mean_squared_error: 5.8209\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 33.8425 - root_mean_squared_error: 5.8174 - val_loss: 33.1615 - val_root_mean_squared_error: 5.7586\n",
      "\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 32.8622 - root_mean_squared_error: 5.7326\n",
      " 8/12 [===================>..........] - ETA: 0s - loss: 32.7069 - root_mean_squared_error: 5.7190\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 33.1615 - root_mean_squared_error: 5.7586\n",
      "\n",
      "  0%|          | 0/4 [00:19<?, ?trial/s, best loss=?]INFO:tensorflow:Assets written to: /var/folders/9c/k2rvfmz92ld8z0rgrcsbrnl40000gn/T/tmp8lwbm8ei/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/9c/k2rvfmz92ld8z0rgrcsbrnl40000gn/T/tmp8lwbm8ei/model/data/model/assets\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:39<01:59, 39.87s/trial, best loss: 5.75860071182251]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohansridhar/miniforge3/envs/google/lib/python3.10/site-packages/_distutils_hack/__init__.py:26: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                                                    \n",
      "\n",
      " 1/46 [..............................] - ETA: 35s - loss: 36.5523 - root_mean_squared_error: 6.0458\n",
      " 5/46 [==>...........................] - ETA: 0s - loss: 35.4603 - root_mean_squared_error: 5.9549 \n",
      "11/46 [======>.......................] - ETA: 0s - loss: 35.2909 - root_mean_squared_error: 5.9406\n",
      "17/46 [==========>...................] - ETA: 0s - loss: 35.3592 - root_mean_squared_error: 5.9464\n",
      "21/46 [============>.................] - ETA: 0s - loss: 35.0576 - root_mean_squared_error: 5.9209\n",
      "24/46 [==============>...............] - ETA: 0s - loss: 35.0749 - root_mean_squared_error: 5.9224\n",
      "27/46 [================>.............] - ETA: 0s - loss: 35.0511 - root_mean_squared_error: 5.9204\n",
      "30/46 [==================>...........] - ETA: 0s - loss: 34.9087 - root_mean_squared_error: 5.9084\n",
      "33/46 [====================>.........] - ETA: 0s - loss: 34.8812 - root_mean_squared_error: 5.9060\n",
      "34/46 [=====================>........] - ETA: 0s - loss: 34.8283 - root_mean_squared_error: 5.9015\n",
      "35/46 [=====================>........] - ETA: 0s - loss: 34.8549 - root_mean_squared_error: 5.9038\n",
      "38/46 [=======================>......] - ETA: 0s - loss: 34.7375 - root_mean_squared_error: 5.8939\n",
      "41/46 [=========================>....] - ETA: 0s - loss: 34.7365 - root_mean_squared_error: 5.8938\n",
      "44/46 [===========================>..] - ETA: 0s - loss: 34.7203 - root_mean_squared_error: 5.8924\n",
      "46/46 [==============================] - ETA: 0s - loss: 34.6965 - root_mean_squared_error: 5.8904\n",
      "46/46 [==============================] - 2s 32ms/step - loss: 34.6965 - root_mean_squared_error: 5.8904 - val_loss: 34.2429 - val_root_mean_squared_error: 5.8517\n",
      "\n",
      "Epoch 2/3                                                                    \n",
      "\n",
      " 1/46 [..............................] - ETA: 0s - loss: 36.2729 - root_mean_squared_error: 6.0227\n",
      " 6/46 [==>...........................] - ETA: 0s - loss: 34.8105 - root_mean_squared_error: 5.9000\n",
      "10/46 [=====>........................] - ETA: 0s - loss: 34.2172 - root_mean_squared_error: 5.8495\n",
      "15/46 [========>.....................] - ETA: 0s - loss: 34.1412 - root_mean_squared_error: 5.8430\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 34.0301 - root_mean_squared_error: 5.8335\n",
      "23/46 [==============>...............] - ETA: 0s - loss: 33.8843 - root_mean_squared_error: 5.8210\n",
      "27/46 [================>.............] - ETA: 0s - loss: 33.7281 - root_mean_squared_error: 5.8076\n",
      "31/46 [===================>..........] - ETA: 0s - loss: 33.6012 - root_mean_squared_error: 5.7967\n",
      "35/46 [=====================>........] - ETA: 0s - loss: 33.4941 - root_mean_squared_error: 5.7874\n",
      "38/46 [=======================>......] - ETA: 0s - loss: 33.3760 - root_mean_squared_error: 5.7772\n",
      "41/46 [=========================>....] - ETA: 0s - loss: 33.3556 - root_mean_squared_error: 5.7754\n",
      "43/46 [===========================>..] - ETA: 0s - loss: 33.3095 - root_mean_squared_error: 5.7714\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 33.2373 - root_mean_squared_error: 5.7652 - val_loss: 32.7844 - val_root_mean_squared_error: 5.7258\n",
      "\n",
      "Epoch 3/3                                                                    \n",
      "\n",
      " 1/46 [..............................] - ETA: 1s - loss: 33.1860 - root_mean_squared_error: 5.7607\n",
      " 4/46 [=>............................] - ETA: 0s - loss: 32.0039 - root_mean_squared_error: 5.6572\n",
      " 7/46 [===>..........................] - ETA: 0s - loss: 31.6679 - root_mean_squared_error: 5.6274\n",
      "11/46 [======>.......................] - ETA: 0s - loss: 32.1902 - root_mean_squared_error: 5.6736\n",
      "15/46 [========>.....................] - ETA: 0s - loss: 32.0402 - root_mean_squared_error: 5.6604\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 32.2095 - root_mean_squared_error: 5.6753\n",
      "23/46 [==============>...............] - ETA: 0s - loss: 32.0345 - root_mean_squared_error: 5.6599\n",
      "27/46 [================>.............] - ETA: 0s - loss: 32.0812 - root_mean_squared_error: 5.6640\n",
      "31/46 [===================>..........] - ETA: 0s - loss: 32.1245 - root_mean_squared_error: 5.6678\n",
      "34/46 [=====================>........] - ETA: 0s - loss: 32.0435 - root_mean_squared_error: 5.6607\n",
      "36/46 [======================>.......] - ETA: 0s - loss: 32.0698 - root_mean_squared_error: 5.6630\n",
      "38/46 [=======================>......] - ETA: 0s - loss: 32.0250 - root_mean_squared_error: 5.6591\n",
      "39/46 [========================>.....] - ETA: 0s - loss: 31.9912 - root_mean_squared_error: 5.6561\n",
      "41/46 [=========================>....] - ETA: 0s - loss: 31.9774 - root_mean_squared_error: 5.6549\n",
      "44/46 [===========================>..] - ETA: 0s - loss: 31.8541 - root_mean_squared_error: 5.6439\n",
      "46/46 [==============================] - 1s 27ms/step - loss: 31.8387 - root_mean_squared_error: 5.6426 - val_loss: 31.3874 - val_root_mean_squared_error: 5.6024\n",
      "\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 31.5358 - root_mean_squared_error: 5.6157\n",
      " 7/12 [================>.............] - ETA: 0s - loss: 31.0298 - root_mean_squared_error: 5.5704\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 31.3874 - root_mean_squared_error: 5.6024\n",
      "\n",
      " 25%|██▌       | 1/4 [00:44<01:59, 39.87s/trial, best loss: 5.75860071182251]INFO:tensorflow:Assets written to: /var/folders/9c/k2rvfmz92ld8z0rgrcsbrnl40000gn/T/tmpno2oubvj/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/9c/k2rvfmz92ld8z0rgrcsbrnl40000gn/T/tmpno2oubvj/model/data/model/assets\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:57<00:53, 26.61s/trial, best loss: 5.602449893951416]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                                                     \n",
      "\n",
      " 1/46 [..............................] - ETA: 29s - loss: 36.1881 - root_mean_squared_error: 6.0157\n",
      " 6/46 [==>...........................] - ETA: 0s - loss: 30.4206 - root_mean_squared_error: 5.5155 \n",
      "10/46 [=====>........................] - ETA: 0s - loss: 25.5784 - root_mean_squared_error: 5.0575\n",
      "14/46 [========>.....................] - ETA: 0s - loss: 20.8221 - root_mean_squared_error: 4.5631\n",
      "17/46 [==========>...................] - ETA: 0s - loss: 17.7407 - root_mean_squared_error: 4.2120\n",
      "20/46 [============>.................] - ETA: 0s - loss: 15.3022 - root_mean_squared_error: 3.9118\n",
      "23/46 [==============>...............] - ETA: 0s - loss: 13.4060 - root_mean_squared_error: 3.6614\n",
      "26/46 [===============>..............] - ETA: 0s - loss: 11.9309 - root_mean_squared_error: 3.4541\n",
      "29/46 [=================>............] - ETA: 0s - loss: 10.7517 - root_mean_squared_error: 3.2790\n",
      "31/46 [===================>..........] - ETA: 0s - loss: 10.1091 - root_mean_squared_error: 3.1795\n",
      "34/46 [=====================>........] - ETA: 0s - loss: 9.2656 - root_mean_squared_error: 3.0439 \n",
      "37/46 [=======================>......] - ETA: 0s - loss: 8.5602 - root_mean_squared_error: 2.9258\n",
      "40/46 [=========================>....] - ETA: 0s - loss: 7.9595 - root_mean_squared_error: 2.8213\n",
      "43/46 [===========================>..] - ETA: 0s - loss: 7.4543 - root_mean_squared_error: 2.7303\n",
      "46/46 [==============================] - ETA: 0s - loss: 7.0314 - root_mean_squared_error: 2.6517\n",
      "46/46 [==============================] - 2s 36ms/step - loss: 7.0314 - root_mean_squared_error: 2.6517 - val_loss: 0.5796 - val_root_mean_squared_error: 0.7613\n",
      "\n",
      "Epoch 2/3                                                                     \n",
      "\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.6715 - root_mean_squared_error: 0.8194\n",
      " 2/46 [>.............................] - ETA: 5s - loss: 0.6523 - root_mean_squared_error: 0.8076\n",
      " 3/46 [>.............................] - ETA: 3s - loss: 0.6411 - root_mean_squared_error: 0.8007\n",
      " 6/46 [==>...........................] - ETA: 1s - loss: 0.6172 - root_mean_squared_error: 0.7856\n",
      " 8/46 [====>.........................] - ETA: 1s - loss: 0.6207 - root_mean_squared_error: 0.7879\n",
      "10/46 [=====>........................] - ETA: 1s - loss: 0.5995 - root_mean_squared_error: 0.7742\n",
      "13/46 [=======>......................] - ETA: 1s - loss: 0.5915 - root_mean_squared_error: 0.7691\n",
      "16/46 [=========>....................] - ETA: 0s - loss: 0.5976 - root_mean_squared_error: 0.7730\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 0.5804 - root_mean_squared_error: 0.7619\n",
      "23/46 [==============>...............] - ETA: 0s - loss: 0.5741 - root_mean_squared_error: 0.7577\n",
      "28/46 [=================>............] - ETA: 0s - loss: 0.5757 - root_mean_squared_error: 0.7587\n",
      "33/46 [====================>.........] - ETA: 0s - loss: 0.5899 - root_mean_squared_error: 0.7680\n",
      "38/46 [=======================>......] - ETA: 0s - loss: 0.5869 - root_mean_squared_error: 0.7661\n",
      "43/46 [===========================>..] - ETA: 0s - loss: 0.5924 - root_mean_squared_error: 0.7697\n",
      "46/46 [==============================] - 1s 21ms/step - loss: 0.5906 - root_mean_squared_error: 0.7685 - val_loss: 0.5679 - val_root_mean_squared_error: 0.7536\n",
      "\n",
      "Epoch 3/3                                                                     \n",
      "\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.6898 - root_mean_squared_error: 0.8306\n",
      " 5/46 [==>...........................] - ETA: 0s - loss: 0.6760 - root_mean_squared_error: 0.8222\n",
      " 8/46 [====>.........................] - ETA: 0s - loss: 0.6192 - root_mean_squared_error: 0.7869\n",
      "11/46 [======>.......................] - ETA: 0s - loss: 0.6067 - root_mean_squared_error: 0.7789\n",
      "15/46 [========>.....................] - ETA: 0s - loss: 0.6059 - root_mean_squared_error: 0.7784\n",
      "18/46 [==========>...................] - ETA: 0s - loss: 0.6223 - root_mean_squared_error: 0.7889\n",
      "22/46 [=============>................] - ETA: 0s - loss: 0.5978 - root_mean_squared_error: 0.7732\n",
      "26/46 [===============>..............] - ETA: 0s - loss: 0.5880 - root_mean_squared_error: 0.7668\n",
      "30/46 [==================>...........] - ETA: 0s - loss: 0.5873 - root_mean_squared_error: 0.7664\n",
      "34/46 [=====================>........] - ETA: 0s - loss: 0.6005 - root_mean_squared_error: 0.7749\n",
      "38/46 [=======================>......] - ETA: 0s - loss: 0.5912 - root_mean_squared_error: 0.7689\n",
      "42/46 [==========================>...] - ETA: 0s - loss: 0.5824 - root_mean_squared_error: 0.7631\n",
      "46/46 [==============================] - ETA: 0s - loss: 0.5852 - root_mean_squared_error: 0.7650\n",
      "46/46 [==============================] - 1s 18ms/step - loss: 0.5852 - root_mean_squared_error: 0.7650 - val_loss: 0.5726 - val_root_mean_squared_error: 0.7567\n",
      "\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.5028 - root_mean_squared_error: 0.7091\n",
      " 7/12 [================>.............] - ETA: 0s - loss: 0.5598 - root_mean_squared_error: 0.7482\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.5726 - root_mean_squared_error: 0.7567\n",
      "\n",
      " 50%|█████     | 2/4 [01:01<00:53, 26.61s/trial, best loss: 5.602449893951416]INFO:tensorflow:Assets written to: /var/folders/9c/k2rvfmz92ld8z0rgrcsbrnl40000gn/T/tmpn3mo6gg4/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/9c/k2rvfmz92ld8z0rgrcsbrnl40000gn/T/tmpn3mo6gg4/model/data/model/assets\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [01:15<00:22, 23.00s/trial, best loss: 0.7566930055618286]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                                                      \n",
      "\n",
      " 75%|███████▌  | 3/4 [01:18<00:22, 23.00s/trial, best loss: 0.7566930055618286]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 13:47:43.076704: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node SGD/AssignVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/46 [..............................] - ETA: 1:19 - loss: 35.9473 - root_mean_squared_error: 5.9956\n",
      " 3/46 [>.............................] - ETA: 1s - loss: 36.9650 - root_mean_squared_error: 6.0799  \n",
      " 5/46 [==>...........................] - ETA: 1s - loss: 35.3740 - root_mean_squared_error: 5.9476\n",
      " 8/46 [====>.........................] - ETA: 0s - loss: 35.5059 - root_mean_squared_error: 5.9587\n",
      "11/46 [======>.......................] - ETA: 0s - loss: 36.1604 - root_mean_squared_error: 6.0134\n",
      "14/46 [========>.....................] - ETA: 0s - loss: 36.6187 - root_mean_squared_error: 6.0513\n",
      "17/46 [==========>...................] - ETA: 0s - loss: 36.3581 - root_mean_squared_error: 6.0298\n",
      "18/46 [==========>...................] - ETA: 0s - loss: 36.2743 - root_mean_squared_error: 6.0228\n",
      "20/46 [============>.................] - ETA: 0s - loss: 36.4874 - root_mean_squared_error: 6.0405\n",
      "21/46 [============>.................] - ETA: 0s - loss: 36.4242 - root_mean_squared_error: 6.0352\n",
      "22/46 [=============>................] - ETA: 0s - loss: 36.4201 - root_mean_squared_error: 6.0349\n",
      "24/46 [==============>...............] - ETA: 0s - loss: 36.4968 - root_mean_squared_error: 6.0413\n",
      "26/46 [===============>..............] - ETA: 0s - loss: 36.4703 - root_mean_squared_error: 6.0391\n",
      "28/46 [=================>............] - ETA: 0s - loss: 36.3551 - root_mean_squared_error: 6.0295\n",
      "30/46 [==================>...........] - ETA: 0s - loss: 36.4322 - root_mean_squared_error: 6.0359\n",
      "32/46 [===================>..........] - ETA: 0s - loss: 36.4235 - root_mean_squared_error: 6.0352\n",
      "34/46 [=====================>........] - ETA: 0s - loss: 36.2976 - root_mean_squared_error: 6.0247\n",
      "37/46 [=======================>......] - ETA: 0s - loss: 36.3517 - root_mean_squared_error: 6.0292\n",
      "41/46 [=========================>....] - ETA: 0s - loss: 36.2553 - root_mean_squared_error: 6.0212\n",
      "45/46 [============================>.] - ETA: 0s - loss: 36.2163 - root_mean_squared_error: 6.0180\n",
      "46/46 [==============================] - ETA: 0s - loss: 36.1959 - root_mean_squared_error: 6.0163\n",
      "46/46 [==============================] - 4s 41ms/step - loss: 36.1959 - root_mean_squared_error: 6.0163 - val_loss: 36.7309 - val_root_mean_squared_error: 6.0606\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      " 1/46 [..............................] - ETA: 1s - loss: 36.6281 - root_mean_squared_error: 6.0521\n",
      " 4/46 [=>............................] - ETA: 0s - loss: 36.3943 - root_mean_squared_error: 6.0328\n",
      " 8/46 [====>.........................] - ETA: 0s - loss: 35.9952 - root_mean_squared_error: 5.9996\n",
      "11/46 [======>.......................] - ETA: 0s - loss: 36.4449 - root_mean_squared_error: 6.0370\n",
      "15/46 [========>.....................] - ETA: 0s - loss: 36.4168 - root_mean_squared_error: 6.0346\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 36.3197 - root_mean_squared_error: 6.0266\n",
      "23/46 [==============>...............] - ETA: 0s - loss: 36.3365 - root_mean_squared_error: 6.0280\n",
      "27/46 [================>.............] - ETA: 0s - loss: 36.3053 - root_mean_squared_error: 6.0254\n",
      "31/46 [===================>..........] - ETA: 0s - loss: 36.3306 - root_mean_squared_error: 6.0275\n",
      "35/46 [=====================>........] - ETA: 0s - loss: 36.0163 - root_mean_squared_error: 6.0014\n",
      "39/46 [========================>.....] - ETA: 0s - loss: 35.9981 - root_mean_squared_error: 5.9998\n",
      "43/46 [===========================>..] - ETA: 0s - loss: 35.9842 - root_mean_squared_error: 5.9987\n",
      "44/46 [===========================>..] - ETA: 0s - loss: 35.9860 - root_mean_squared_error: 5.9988\n",
      "46/46 [==============================] - ETA: 0s - loss: 35.9539 - root_mean_squared_error: 5.9962\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 35.9539 - root_mean_squared_error: 5.9962 - val_loss: 36.4807 - val_root_mean_squared_error: 6.0399\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      " 1/46 [..............................] - ETA: 1s - loss: 34.1219 - root_mean_squared_error: 5.8414\n",
      " 5/46 [==>...........................] - ETA: 0s - loss: 35.9863 - root_mean_squared_error: 5.9989\n",
      " 8/46 [====>.........................] - ETA: 0s - loss: 35.8431 - root_mean_squared_error: 5.9869\n",
      "11/46 [======>.......................] - ETA: 0s - loss: 36.1507 - root_mean_squared_error: 6.0125\n",
      "14/46 [========>.....................] - ETA: 0s - loss: 36.2867 - root_mean_squared_error: 6.0238\n",
      "17/46 [==========>...................] - ETA: 0s - loss: 36.2561 - root_mean_squared_error: 6.0213\n",
      "20/46 [============>.................] - ETA: 0s - loss: 36.3023 - root_mean_squared_error: 6.0251\n",
      "23/46 [==============>...............] - ETA: 0s - loss: 35.9690 - root_mean_squared_error: 5.9974\n",
      "26/46 [===============>..............] - ETA: 0s - loss: 36.2106 - root_mean_squared_error: 6.0175\n",
      "29/46 [=================>............] - ETA: 0s - loss: 36.1406 - root_mean_squared_error: 6.0117\n",
      "32/46 [===================>..........] - ETA: 0s - loss: 36.1066 - root_mean_squared_error: 6.0089\n",
      "35/46 [=====================>........] - ETA: 0s - loss: 36.0104 - root_mean_squared_error: 6.0009\n",
      "40/46 [=========================>....] - ETA: 0s - loss: 35.7360 - root_mean_squared_error: 5.9780\n",
      "44/46 [===========================>..] - ETA: 0s - loss: 35.7702 - root_mean_squared_error: 5.9808\n",
      "46/46 [==============================] - 1s 23ms/step - loss: 35.7144 - root_mean_squared_error: 5.9762 - val_loss: 36.2332 - val_root_mean_squared_error: 6.0194\n",
      "\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 36.0336 - root_mean_squared_error: 6.0028\n",
      " 8/12 [===================>..........] - ETA: 0s - loss: 35.7120 - root_mean_squared_error: 5.9760\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 36.2332 - root_mean_squared_error: 6.0194\n",
      "\n",
      " 75%|███████▌  | 3/4 [01:24<00:22, 23.00s/trial, best loss: 0.7566930055618286]INFO:tensorflow:Assets written to: /var/folders/9c/k2rvfmz92ld8z0rgrcsbrnl40000gn/T/tmp1lf7_e_e/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/9c/k2rvfmz92ld8z0rgrcsbrnl40000gn/T/tmp1lf7_e_e/model/data/model/assets\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:38<00:00, 24.65s/trial, best loss: 0.7566930055618286]\n",
      "INFO:tensorflow:Assets written to: /var/folders/9c/k2rvfmz92ld8z0rgrcsbrnl40000gn/T/tmpxcvj5fmm/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/9c/k2rvfmz92ld8z0rgrcsbrnl40000gn/T/tmpxcvj5fmm/model/data/model/assets\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'lr': 0.0041718120514133315, 'momentum': 0.7326876258589665}\n",
      "Best eval rmse: 0.7566930055618286\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"wine-quality\")\n",
    "with mlflow.start_run():\n",
    "    # Conduct the hyperparameter search using Hyperopt\n",
    "    trials=Trials()\n",
    "    best=fmin(\n",
    "        fn=objective,\n",
    "        space=space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=4,\n",
    "        trials=trials\n",
    "    )\n",
    "\n",
    "    # Fetch the details of the best run\n",
    "    best_run = sorted(trials.results, key=lambda x: x[\"loss\"])[0]\n",
    "\n",
    "    # Log the best parameters, loss, and model\n",
    "    mlflow.log_params(best)\n",
    "    mlflow.log_metric(\"eval_rmse\", best_run[\"loss\"])\n",
    "    mlflow.tensorflow.log_model(best_run[\"model\"], \"model\", signature=signature)\n",
    "\n",
    "    # Print out the best parameters and corresponding loss\n",
    "    print(f\"Best parameters: {best}\")\n",
    "    print(f\"Best eval rmse: {best_run['loss']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\UDemy Final\\MlFlowStarter\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 999.77it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.2569876],\n",
       "       [7.2708473],\n",
       "       [5.690359 ],\n",
       "       ...,\n",
       "       [6.881361 ],\n",
       "       [6.6991577],\n",
       "       [4.748927 ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Inferencing\n",
    "\n",
    "from mlflow.models import validate_serving_input\n",
    "\n",
    "model_uri = 'runs:/9e0b52639ab44e6a864f5bd2f460fe42/model'\n",
    "\n",
    "# The logged model does not contain an input_example.\n",
    "# Manually generate a serving payload to verify your model prior to deployment.\n",
    "from mlflow.models import convert_input_example_to_serving_input\n",
    "\n",
    "# Define INPUT_EXAMPLE via assignment with your own input example to the model\n",
    "# A valid input example is a data instance suitable for pyfunc prediction\n",
    "serving_payload = convert_input_example_to_serving_input(test_x)\n",
    "\n",
    "# Validate the serving payload works on the model\n",
    "validate_serving_input(model_uri, serving_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.2569876],\n",
       "       [7.2708473],\n",
       "       [5.690359 ],\n",
       "       ...,\n",
       "       [6.881361 ],\n",
       "       [6.6991577],\n",
       "       [4.748927 ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model as a PyFuncModel.\n",
    "model_uri = 'runs:/9e0b52639ab44e6a864f5bd2f460fe42/model'\n",
    "loaded_model = mlflow.pyfunc.load_model(model_uri)\n",
    "\n",
    "# Predict on a Pandas DataFrame.\n",
    "import pandas as pd\n",
    "loaded_model.predict(pd.DataFrame(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'wine-quality'.\n",
      "Created version '1' of model 'wine-quality'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1727548664831, current_stage='None', description=None, last_updated_timestamp=1727548664831, name='wine-quality', run_id='9e0b52639ab44e6a864f5bd2f460fe42', run_link=None, source='file:///e:/UDemy%20Final/MlFlowStarter/2-DLMLFLOW/mlruns/929139454095764868/9e0b52639ab44e6a864f5bd2f460fe42/artifacts/model', status='READY', status_message=None, tags={}, user_id=None, version=1>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Register in the model registry\n",
    "mlflow.register_model(model_uri,\"wine-quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "google",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
